{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6cbf5d6",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## Exemplo 3 - Diagnóstico médico: Problemas Ortopédicos na Coluna Vertebral\n",
    "\n",
    "Esse dataset contém dados sobre problemas ortopédicos na coluna vertebral, diagnosticados no Centre Médico-Chirurgical de Réadaptation des Massues, em Lyon, France. Contém 6 atributos biomecânicos para 310 entradas anonimizadas, sendo 100 de pacientes considerados sem problemas (Normal - NO), 60 de pacientes com Hérnia de Disco (Disk Hernia - DH) e 150 de pacientes com Espondilolistese (Spondylolisthesis - SL). \n",
    "\n",
    "O dataset está disponível em https://www.openml.org/d/1523"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6177c1",
   "metadata": {},
   "source": [
    "### Exemplo 3 - Primeiro passo: Carregar dados e Realizar a Análise Exploratória\n",
    "\n",
    "Para importar dados do OpenML podemos usar uma função pronta na biblioteca do Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3d649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e2d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = fetch_openml(data_id=1523)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af648d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3078ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8384a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dados.data,columns=dados.feature_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c56091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ccf533",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(dados.target).count('1'))\n",
    "print(list(dados.target).count('2'))\n",
    "print(list(dados.target).count('3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map={\n",
    "    '1':'Disk Hernia',\n",
    "    '2':'Normal',\n",
    "    '3':'Spondylolisthesis'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad5784",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnostic'] = [target_map[target] for target in dados.target]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02fdade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba6db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='diagnostic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dbdf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('diagnostic').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2a5084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('diagnostic').std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c911aa4",
   "metadata": {},
   "source": [
    "### Segundo passo: separar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99ed1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolhendo as colunas preditivas e alvo\n",
    "x = df.drop(columns = ['diagnostic'])\n",
    "y = df['diagnostic'] # Classe alvo\n",
    "\n",
    "# Dividindo conjunto de treinamento e conjunto de teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4df752",
   "metadata": {},
   "source": [
    "### Terceiro passo: transformar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56cb693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327b9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o Escalonador\n",
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Treinando o escalonador\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# Usando o escalonador treinado para transformar os dados\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b60f08",
   "metadata": {},
   "source": [
    "### Quarto passo: treinar o algoritmo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6bc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()  # Criamos o objeto do classificador (não mudamos nenhum hiperpârametro)\n",
    "\n",
    "lda.fit(x_train_scaled, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baa0536",
   "metadata": {},
   "source": [
    "### Quinto passo: testar e avaliar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587fdbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceba que estamos passando apenas o x de teste, afinal o algoritmo é que nos dira qual é o y \n",
    "y_predicoes = lda.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d85ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusao = confusion_matrix(y_true = y_test,\n",
    "                                   y_pred = y_predicoes,\n",
    "                                   labels=['Disk Hernia','Normal','Spondylolisthesis'])\n",
    "\n",
    "# plotando uma figura com a matriz de confusao\n",
    "figure = plt.figure(figsize=(15, 5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = matriz_confusao, \n",
    "                              display_labels=['Disk Hernia','Normal','Spondylolisthesis'])\n",
    "disp.plot(values_format='d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metricas de precisão, revocação, f1-score e acurácia.\n",
    "print(classification_report(y_test, y_predicoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa367d0e",
   "metadata": {},
   "source": [
    "Obtivemos, no geral, uma acurácia baixa.\n",
    "\n",
    "Além disso nosso Recall em relação a Hérnia de Disco é muito baixo (temos muitos falsos negativos - pacientes que não tem hérnia de disco classificados com hérnia de disco);\n",
    "\n",
    "Nossa precisão para Normal também está baixa (temos muito falsos positivos - pacientes classificados como normal mas que tem algum problema);\n",
    "\n",
    "Precisamos voltar ao **Passo 4** e mexer nos hiperparâmetros do nosso algoritmo ou escolher outro algoritmo de classificação. Vejamos outros algoritmos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa8dd0",
   "metadata": {},
   "source": [
    "### De volta ao passo 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf23bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Gaussiano\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Passo 4 - Treinar o Classificador\n",
    "gnb = GaussianNB()  # Criamos o objeto do classificador (não mudamos nenhum hiperpârametro)\n",
    "gnb.fit(x_train, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# Passo 5 - Testar o Classificador\n",
    "y_predicoes = gnb.predict(x_test) \n",
    "\n",
    "# Metricas de precisão, revocação, f1-score e acurácia.\n",
    "print(classification_report(y_test, y_predicoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d27f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-vizinhos mais próximos (KNN)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Passo 4 - Treinar o Classificador\n",
    "knn = KNeighborsClassifier() # Criando classificador (sem nenhum hiperparametro)\n",
    "knn.fit(x_train, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# Passo 5 - Testar o Classificador\n",
    "y_predicoes = knn.predict(x_test) \n",
    "\n",
    "# Metricas de precisão, revocação, f1-score e acurácia.\n",
    "print(classification_report(y_test, y_predicoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Árvore de Decisão\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Passo 4 - Treinar o Classificador\n",
    "dtree = DecisionTreeClassifier() # Criando classificador (sem nenhum hiperparametro)\n",
    "dtree.fit(x_train, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# Passo 5 - Testar o Classificador\n",
    "y_predicoes = dtree.predict(x_test) \n",
    "\n",
    "# Metricas de precisão, revocação, f1-score e acurácia.\n",
    "print(classification_report(y_test, y_predicoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952fc90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Passo 4 - Treinar o Classificador\n",
    "rf = RandomForestClassifier(random_state=42) # Criando classificador (hiperparametro de seed)\n",
    "rf.fit(x_train, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# Passo 5 - Testar o Classificador\n",
    "y_predicoes = rf.predict(x_test) \n",
    "\n",
    "# Metricas de precisão, revocação, f1-score e acurácia.\n",
    "print(classification_report(y_test, y_predicoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Máquina de Vetor Suporte\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Passo 4 - Treinar o Classificador\n",
    "svm = SVC() # Criando classificador (sem nenhum hiperparametro)\n",
    "svm.fit(x_train, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# Passo 5 - Testar o Classificador\n",
    "y_predicoes = svm.predict(x_test) \n",
    "\n",
    "# Metricas de precisão, revocação, f1-score e acurácia.\n",
    "print(classification_report(y_test, y_predicoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf77549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressão Logística \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Passo 4 - Treinar o Classificador\n",
    "logreg = LogisticRegression() # Criando classificador (sem nenhum hiperparametro)\n",
    "logreg.fit(x_train, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# Passo 5 - Testar o Classificador\n",
    "y_predicoes = logreg.predict(x_test) \n",
    "\n",
    "# Metricas de precisão, revocação, f1-score e acurácia.\n",
    "print(classification_report(y_test, y_predicoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dfc2ce",
   "metadata": {},
   "source": [
    "Nós testamos diferentes algoritmos de classificação. \n",
    "\n",
    "Perceba que a forma básica de todos eles é extremamente igual.\n",
    "\n",
    "Os nuances começam a aparecer quando olhamos em mais detalhes os hiperparâmetros e como cada algoritmo funciona internamente.\n",
    "\n",
    "Entre na documentação de cada um dos classificadores e tente usar diferentes hiperparâmetros para ver se você consegue melhorar a performance de algum deles.\n",
    "\n",
    "Outra coisa é que certos algoritmos funcionam melhor se os dados fornecidos seguirem determinadas propriedades. Por isso é muito comum fazer uma etapa de pré-processamento dos dados na qual os dados são **transformados** para seguir determinada característica. É nesta etapa que fazemos os **escalonamento** dos dados. Volte ao **passo 3** e veja se o escalonamento influencia a resultado para cada um dos algoritmos testados.\n",
    "\n",
    "Outro ponto é que podemos realizar uma busca exaustiva sobre quais são os melhores hipeparâmetros. Técnicas comuns para se fazer isso são o **GridSearch**, o **RandomSearch**, e a **Validação Cruzada**. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
