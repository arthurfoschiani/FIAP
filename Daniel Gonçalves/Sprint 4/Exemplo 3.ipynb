{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6659e3fd",
   "metadata": {},
   "source": [
    "## Carregando base dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba07c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23588b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('IPODataFull.csv', sep=',', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6174b717",
   "metadata": {},
   "source": [
    "## Selecionando as colunas necessárias para a análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando as colunas que utilizaremos para a análise\n",
    "data = data[['DaysBetterThanSP','daysProfit','Year','Month','Day','dayOfWeek','closeDay0', 'Safe']]\n",
    "# Renomear elas para o português para melhor entendimento\n",
    "data = data.rename(columns={\n",
    "#     'Symbol': 'Ticker',\n",
    "    'DaysBetterThanSP': 'DiasMelhoresQueSP',\n",
    "    'daysProfit': 'DiasDeLucro',\n",
    "    'Year': 'Ano',\n",
    "    'Month': 'Mês',\n",
    "    'Day': 'Dia',\n",
    "    'dayOfWeek': 'DiaDaSemana',\n",
    "    'closeDay0': 'FechamentoDia0',\n",
    "    'Safe': 'Seguro'\n",
    "})\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4132483",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Informações de cada coluna para análise\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7817077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descrição de cada coluna\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f6e232",
   "metadata": {},
   "source": [
    "## Visualizando o histograma das colunas para análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56897919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos visualizar o histograma para entendermos como cada dado de comporta\n",
    "dados = data.drop(columns = ['Seguro'])\n",
    "dados.hist(figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2039082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('De 3761 empresas, {} delas foram consideradas seguro de investir'.format(list(data['Seguro']).count(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d30b9d",
   "metadata": {},
   "source": [
    "### Vamos gerar algumas estatísticas e visualizações exploratórias dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a668dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de disperção para entendermso como os dados de relacionam\n",
    "sns.pairplot(data, hue='Seguro')\n",
    "plt.show()\n",
    "\n",
    "# Dentro da coluna 'Seguro', que é a nossa de coluna de predição, realizamos as seguintes análises\n",
    "display(data.groupby('Seguro').mean())\n",
    "display(data.groupby('Seguro').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b16bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.round(1)\n",
    "# Visualizando gráfico de heatmap para entendermos a correlação precisa entre cada coluna\n",
    "sns.heatmap(data_sample.corr(), cmap='coolwarm', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d91a7f7",
   "metadata": {},
   "source": [
    "Com base na análise dos gráficos, constatamos que a coluna 'DiasMelhoresQueSP' apresentava uma forte correlação com a coluna de seguro. Essa correlação poderia afetar negativamente a precisão da nossa análise preditiva, pois os dados estavam relacionados de forma não linear. Por essa razão, realizamos dois testes utilizando modelos de aprendizado de máquina de classificação, e em ambos os casos, obtivemos uma acurácia de 100%.\n",
    "\n",
    "Após essa avaliação, concluímos que a coluna 'DiasMelhoresQueSP' não acrescentava informações relevantes à análise de classificação, podendo, na verdade, estar interferindo na precisão dos resultados. Sendo assim, decidimos remover essa coluna do conjunto de dados para evitar interferências indesejadas nos resultados da análise preditiva."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cbb9a1",
   "metadata": {},
   "source": [
    "# Aprendizado de máquina supervisionado de classificação (preditivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c74814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo as colunas de resposta\n",
    "x = data.drop(columns = ['Seguro', 'DiasMelhoresQueSP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8e58b6",
   "metadata": {},
   "source": [
    "### Predição das coluna \"Seguro\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499df969",
   "metadata": {},
   "source": [
    "### Dividindo conjunto de treinamento e conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Seguro'] # Classe alvo\n",
    "\n",
    "# Dividindo conjunto de treinamento e conjunto de teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af38191",
   "metadata": {},
   "source": [
    "###  Transformar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a258cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o Escalonador\n",
    "scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Treinando o escalonador\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# Usando o escalonador treinado para transformar os dados\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa759a",
   "metadata": {},
   "source": [
    "### Decidimos não utilizar escalonamento\n",
    "\n",
    "Após realizarmos testes com o modelo em questão, observamos que a técnica de escalonamento não apresentou melhorias significativas nos resultados das predições. Em vista disso, optamos por não utilizá-la neste caso específico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e068951",
   "metadata": {},
   "source": [
    "### Treinar o algoritmo com diferentes modelos de predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cd5a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557a701",
   "metadata": {},
   "source": [
    "#### Classificador Bayesianos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bee201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Gaussiano\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Passo 4 - Treinar o Classificador\n",
    "gnb = GaussianNB()  # Criamos o objeto do classificador (não mudamos nenhum hiperpârametro)\n",
    "gnb.fit(x_train, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# Passo 5 - Testar o Classificador\n",
    "y_predicoes = gnb.predict(x_test) \n",
    "\n",
    "# Metricas de precisão, revocação, f1-score e acurácia.\n",
    "print(classification_report(y_test, y_predicoes))\n",
    "\n",
    "matriz_confusao = confusion_matrix(y_true = y_test,\n",
    "                                   y_pred = y_predicoes)\n",
    "\n",
    "figure = plt.figure(figsize=(15, 5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = matriz_confusao,\n",
    "                             display_labels = ['Não Seguro','Seguro'])\n",
    "disp.plot(values_format='d') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a2b180",
   "metadata": {},
   "source": [
    "#### Classificador KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc876be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Treinar o Classificador\n",
    "knn = KNeighborsClassifier() # Criando classificador\n",
    "knn.fit(x_train, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# Testar o Classificador\n",
    "y_predicoes = knn.predict(x_test_scaled) \n",
    "\n",
    "print(classification_report(y_test, y_predicoes))\n",
    "\n",
    "# Criando matriz de confusão para comparar o valor da predição com o real valor\n",
    "matriz_confusao = confusion_matrix(y_true = y_test,\n",
    "                                   y_pred = y_predicoes)\n",
    "\n",
    "figure = plt.figure(figsize=(15, 5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = matriz_confusao,\n",
    "                             display_labels = ['Não Seguro','Seguro'])\n",
    "disp.plot(values_format='d') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f160b4",
   "metadata": {},
   "source": [
    "#### Árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e9b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Treinar o Classificador\n",
    "dtree = DecisionTreeClassifier() # Criando classificador\n",
    "dtree.fit(x_train, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# Testar o Classificador\n",
    "y_predicoes = dtree.predict(x_test) \n",
    "\n",
    "print(classification_report(y_test, y_predicoes))\n",
    "\n",
    "# Criando matriz de confusão para comparar o valor da predição com o real valor\n",
    "matriz_confusao = confusion_matrix(y_true = y_test,\n",
    "                                   y_pred = y_predicoes)\n",
    "\n",
    "figure = plt.figure(figsize=(15, 5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = matriz_confusao,\n",
    "                             display_labels = ['Não Seguro','Seguro'])\n",
    "disp.plot(values_format='d') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f2806",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Treinar o Classificador\n",
    "rf = RandomForestClassifier(random_state=42) # Criando classificador (hiperparametro de seed)\n",
    "rf.fit(x_train, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# Testar o Classificador\n",
    "y_predicoes = rf.predict(x_test) \n",
    "\n",
    "print(classification_report(y_test, y_predicoes))\n",
    "\n",
    "# Criando matriz de confusão para comparar o valor da predição com o real valor\n",
    "matriz_confusao = confusion_matrix(y_true = y_test,\n",
    "                                   y_pred = y_predicoes)\n",
    "\n",
    "figure = plt.figure(figsize=(15, 5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = matriz_confusao,\n",
    "                             display_labels = ['Não Seguro','Seguro'])\n",
    "disp.plot(values_format='d') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d18bce",
   "metadata": {},
   "source": [
    "#### Máquina de vetor suporte (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Treinar o Classificador\n",
    "svm = SVC() # Criando classificador\n",
    "svm.fit(x_train, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# Testar o Classificador\n",
    "y_predicoes = svm.predict(x_test) \n",
    "\n",
    "print(classification_report(y_test, y_predicoes))\n",
    "\n",
    "# Criando matriz de confusão para comparar o valor da predição com o real valor\n",
    "matriz_confusao = confusion_matrix(y_true = y_test,\n",
    "                                   y_pred = y_predicoes)\n",
    "\n",
    "figure = plt.figure(figsize=(15, 5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = matriz_confusao,\n",
    "                             display_labels = ['Não Seguro','Seguro'])\n",
    "disp.plot(values_format='d') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f6d9c",
   "metadata": {},
   "source": [
    "#### Classificador por regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a378f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Treinar o Classificador\n",
    "logreg = LogisticRegression() # Criando classificador\n",
    "logreg.fit(x_train, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# Testar o Classificador\n",
    "y_predicoes = logreg.predict(x_test) \n",
    "\n",
    "print(classification_report(y_test, y_predicoes))\n",
    "\n",
    "# Criando matriz de confusão para comparar o valor da predição com o real valor\n",
    "matriz_confusao = confusion_matrix(y_true = y_test,\n",
    "                                   y_pred = y_predicoes)\n",
    "\n",
    "figure = plt.figure(figsize=(15, 5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = matriz_confusao,\n",
    "                             display_labels = ['Não Seguro','Seguro'])\n",
    "disp.plot(values_format='d') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d5761d",
   "metadata": {},
   "source": [
    "### Análise\n",
    "\n",
    "Após a análise dos modelos de predição, observamos que o Random Forest obteve a maior acurácia, alcançando 88%. Acreditamos que o desempenho superior deste modelo pode ser atribuído à sua capacidade de lidar com dados de alta dimensionalidade e muitas variáveis, além de apresentar menor tendência ao overfitting em comparação com outros modelos.\n",
    "\n",
    "O uso de aleatorização e bootstrapping durante o treinamento do modelo também contribuiu para reduzir o impacto de outliers e variáveis irrelevantes, aumentando o desempenho geral do modelo.\n",
    "\n",
    "Analisando as métricas de precisão e recall, observamos que o modelo teve um desempenho excelente na previsão da classe \"0\", com uma precisão de 90% e um recall de 96%. Isso significa que o modelo foi capaz de prever corretamente a classe \"0\" na maioria das vezes e identificar corretamente a maioria das observações reais desta classe.\n",
    "\n",
    "Por outro lado, o modelo apresentou um desempenho inferior na previsão da classe \"1\", com uma precisão de 72% e um recall de 44%. Isso indica que, embora o modelo tenha acertado a classe \"1\" na maioria das vezes, ele teve dificuldade em identificar corretamente as observações reais desta classe.\n",
    "\n",
    "Portanto, é importante salientar que, embora o Random Forest tenha sido o melhor modelo em termos de acurácia geral, outras métricas como recall e F1-score podem ser mais relevantes dependendo da aplicação prática e da importância relativa das classes. Assim, é importante avaliar cuidadosamente as métricas para selecionar o modelo mais adequado para a tarefa de classificação em questão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3343b",
   "metadata": {},
   "source": [
    "# Aprendizado de máquina não supervisionado de agrupamento (descritivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch   # Dendograma# Algoritmos de Agrupamento\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Avaliacao de desemepnho\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d531e7",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d090213",
   "metadata": {},
   "source": [
    "Para este modelo, primeiro vamos escolher a quantidade de grupos de separação de dados (clusters) usando o método do \"cotovelo\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1972c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(range(1, 10))\n",
    "\n",
    "# Armazena o SSE (soma dos erros quadraticos) para cada quantidade de k\n",
    "sse = []\n",
    "\n",
    "# Roda o K-means para cada k fornecido\n",
    "for i in k:\n",
    "    kmeans = KMeans(n_clusters=i, random_state=0)\n",
    "    kmeans.fit(data[['DiasMelhoresQueSP','DiasDeLucro']])\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "# Plota o gráfico com a soma dos erros quadraticos\n",
    "plt.plot(k, sse, '-o')\n",
    "plt.xlabel(r'Número de clusters')\n",
    "plt.ylabel('Inércia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb935d7",
   "metadata": {},
   "source": [
    "##### Agora sim!\n",
    "Optamos por dividir os dados em somente três grupos, já que, a partir do terceiro grupo, a diferença na soma do erro quadrático diminui muito pouco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ce372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o modelo de clusterizacao.\n",
    "kmeans = KMeans(n_clusters=3,random_state=0)\n",
    "\n",
    "#Implementando o K-Means nos dados:\n",
    "kmeans.fit(data[['DiasMelhoresQueSP','DiasDeLucro']])\n",
    "\n",
    "#Salvando os centroides de cada cluster\n",
    "centroides = kmeans.cluster_centers_\n",
    "\n",
    "#Salvando os labels dos clusters para cada exemplo\n",
    "kmeans_labels = kmeans.predict(data[['DiasMelhoresQueSP','DiasDeLucro']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07906287",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(kmeans_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b337bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ee2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os dados identificando com os seus clusters\n",
    "plt.scatter(data[['DiasMelhoresQueSP']],data[['DiasDeLucro']], c=kmeans_labels, alpha=0.5, cmap='rainbow')\n",
    "plt.xlabel('Dias Melhores que SP')\n",
    "plt.ylabel('Dias de lucro')\n",
    "# Plotando os centroides\n",
    "plt.scatter(centroides[:, 0], centroides[:, 1], c='black', marker='X', s=200, alpha=0.5)\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c54e04",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo:\n",
    "dbscan = DBSCAN(eps=8, min_samples=20)\n",
    "# Ajustando aos dados\n",
    "dbscan.fit(data[['DiasMelhoresQueSP','DiasDeLucro']])\n",
    "\n",
    "dbscan_labels = dbscan.labels_\n",
    "dbscan_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando o grafico:\n",
    "plt.scatter(data[['DiasMelhoresQueSP']],data[['DiasDeLucro']], c=dbscan_labels, alpha=0.5)\n",
    "plt.xlabel('Dias Melhores QueSP')\n",
    "plt.ylabel('Dias De Lucro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5397bee1",
   "metadata": {},
   "source": [
    "#### Plotando o grafico sem os outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c53f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Mascara para outlier\n",
    "mascara = dbscan_labels>=0\n",
    "\n",
    "# Plotando o gráfico\n",
    "plt.scatter(data[['DiasMelhoresQueSP']][mascara],data[['DiasDeLucro']][mascara], c=dbscan_labels[mascara], alpha=0.5, cmap='rainbow')\n",
    "plt.xlabel('Dias Melhores QueSP')\n",
    "plt.ylabel('Dias De Lucro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d4dca7",
   "metadata": {},
   "source": [
    "### Agrupamento hierárquico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "model = AgglomerativeClustering(n_clusters=3,linkage='ward')\n",
    "\n",
    "model.fit(data[['DiasMelhoresQueSP','DiasDeLucro']])\n",
    "hierarquico_labels = model.labels_\n",
    "hierarquico_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotando os dados identificando com os seus clusters\n",
    "plt.scatter(data[['DiasMelhoresQueSP']],data[['DiasDeLucro']], c=hierarquico_labels, alpha=0.5, cmap='rainbow')\n",
    "plt.xlabel('Dias Melhores Que SP')\n",
    "plt.ylabel('Dias De Lucro')\n",
    "# plotando os centroides\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dendrogram = sch.dendrogram(sch.linkage(data[['DiasMelhoresQueSP','DiasDeLucro']], method = 'ward'))\n",
    "plt.title('Dendrogam', fontsize = 20)\n",
    "plt.xlabel('Dias')\n",
    "plt.ylabel('Distância Euclidiana')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e82a1",
   "metadata": {},
   "source": [
    "O dendrograma é uma ferramenta visual útil para avaliar a estrutura dos clusters em um algoritmo de agrupamento hierárquico. Ele representa a hierarquia de fusões de clusters, onde os clusters individuais são unidos para formar clusters maiores.\n",
    "\n",
    "A partir deste dendrograma gerado, podemos observar a distância euclidiana entre os clusters ao longo do eixo y. Quanto mais alta a distância, menos semelhantes são os pontos em cada cluster. É possível ver também que os pontos são agrupados em clusters em diferentes níveis do dendrograma, o que indica diferentes níveis de agrupamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea904f",
   "metadata": {},
   "source": [
    "## Avaliando o Desempenho dos Algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce5ccc",
   "metadata": {},
   "source": [
    "##### (a) Usando o **Adjusted Rand Index**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378a604",
   "metadata": {},
   "source": [
    "Comparação entre K-Means e Agrupamento Hierarquico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80588b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(kmeans_labels,hierarquico_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7140d9fa",
   "metadata": {},
   "source": [
    "Comparação entre K-Means e DBSCAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bace20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(kmeans_labels,dbscan_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921fea39",
   "metadata": {},
   "source": [
    "Comparação entre Agrupamento Hierarquico e o DBSCAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(hierarquico_labels,dbscan_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6600a",
   "metadata": {},
   "source": [
    "O ARI mede a semelhança entre dois conjuntos de rótulos de clusters. Valores próximos de 1 indicam que os rótulos atribuídos pelos algoritmos são semelhantes, enquanto valores próximos de 0 indicam que eles são aleatórios ou não relacionados.\n",
    "\n",
    "De acordo com os resultados, o ARI para a comparação entre K-Means e Agrupamento Hierárquico é alto (0,75), o que sugere que esses algoritmos têm uma boa concordância nos rótulos de cluster atribuídos aos dados. No entanto, os valores de ARI para as outras comparações são bastante baixos. Em particular, a comparação entre K-Means e DBSCAN tem um valor de ARI de apenas 0,038, o que sugere que esses algoritmos são bastante diferentes na atribuição de rótulos de cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47580ccd",
   "metadata": {},
   "source": [
    "##### (b) Avaliando a métrica de Silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d42f31",
   "metadata": {},
   "source": [
    "KMEANS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(data[['DiasMelhoresQueSP','DiasDeLucro']],kmeans_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c611f0",
   "metadata": {},
   "source": [
    "DBSCAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b86d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(data[['DiasMelhoresQueSP','DiasDeLucro']],dbscan_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a9157",
   "metadata": {},
   "source": [
    "Agrupamento Hierarquico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578a59fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(data[['DiasMelhoresQueSP','DiasDeLucro']],hierarquico_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead7bb56",
   "metadata": {},
   "source": [
    "A métrica de Silhouette mede o quão bem cada ponto de dados se encaixa no seu próprio cluster em comparação com outros clusters. Valores positivos indicam que os pontos estão bem agrupados, enquanto valores negativos indicam que eles podem estar no cluster errado.\n",
    "\n",
    "Os resultados fornecidos mostram que o K-Means tem o valor de Silhouette mais alto (0,539), seguido pelo Agrupamento Hierárquico (0,506), enquanto o DBSCAN tem um valor negativo (-0,110). Isso sugere que o K-Means e o Agrupamento Hierárquico são melhores na formação de clusters com pontos bem agrupados, enquanto o DBSCAN pode ter problemas em atribuir pontos a um cluster apropriado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
